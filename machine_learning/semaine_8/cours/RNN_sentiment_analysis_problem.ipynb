{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ovxFKAAj2to"
   },
   "source": [
    "# MLA 703. RNN-LSTM et architectures avancées [Analyse de sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWLHKoG6j2tp"
   },
   "outputs": [],
   "source": [
    "# Dans ce notebook, nous allons nous intéresser à des tâches d'analyse de sentiments\n",
    "# -> c'est à dire prédire un label de sentiment (ici positif ou négatif) à partir d'un texte\n",
    "\n",
    "# Ce notebook vise à approfondir : \n",
    "# - L'application du DL sur des données textuelles\n",
    "# - La compréhension des architectures RNN avancées comme les LSTM et les mécanismes d'attention\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTC0SJwEj2tq"
   },
   "source": [
    "# Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DfDpiDv4j2tq"
   },
   "outputs": [],
   "source": [
    "# On importe les librairies usuelless\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# On désactive les warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt2bfDIwoZ_3"
   },
   "source": [
    "# Fonction utile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SfGk7PHXoV7w"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  # On trace la loss et l'accuracy du modèle\n",
    "  # On trace l'évolution de l'accuracy\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy']) \n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "  # On trace l'évolution de la loss\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D4yyKoT-o8hi"
   },
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "\n",
    "  # On prédit sur l'ensemble de test\n",
    "\n",
    "  # On prédit sur les données de test\n",
    "  y_hat = model.predict(x_test)\n",
    "\n",
    "  # On tranforme les prédictions en labels\n",
    "  i_pos = [i for i in range(len(y_hat)) if y_hat[i]>0]\n",
    "  i_neg = [i for i in range(len(y_hat)) if y_hat[i]<=0]\n",
    "\n",
    "  y_pred   = np.zeros(len(y_hat))\n",
    "  y_pred[i_pos] = 1\n",
    "  y_pred[i_neg] = 0\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwOjTZYej2tq"
   },
   "source": [
    "## 1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PcQTK_8j2tq",
    "outputId": "87bbad90-b150-4c27-dfc0-146f19c9783a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 14:51:00.978271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-28 14:51:00.978288: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# On charge directement la base IMDB par les datasets de Keras\n",
    "# La méthode load_date possède pas mal d'options et de propriétés intéressantes (voir description) :\n",
    "# 1) Sépare les jeux d'entrainement et de test\n",
    "# 2) num_words : Top most frequent words to consider.\n",
    "# 3) skip_top : Top most frequent words to ignore (they will appear as oov_char value in the sequence data).\n",
    "# 4) maxlen : Maximum sequence length. Any longer sequence will be truncated.\n",
    "# 5) seed : Seed for reproducible data shuffling.\n",
    "# 6) start_char : The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.\n",
    "# 7) oov_char : words that were cut out because of the num_words or skip_top limit will be replaced with this character.\n",
    "# 8) index_from : Index actual words with this index and higher.\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "num_words = 5000\n",
    "max_len   =  100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words,\n",
    "                                                      maxlen=max_len)\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 2, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 2, 10, 10]),\n",
       "       list([1, 54, 13, 1610, 14, 20, 13, 69, 55, 364, 1398, 21, 54, 13, 219, 12, 13, 1706, 15, 4, 20, 16, 329, 6, 176, 329, 74, 51, 13, 873, 4, 156, 71, 78, 4, 2, 322, 16, 31, 7, 4, 249, 4, 65, 16, 38, 379, 12, 100, 157, 18, 6, 910, 20, 549, 18, 4, 1496, 21, 14, 31, 9, 24, 6, 212, 12, 9, 6, 1322, 991, 7, 3002, 4, 425, 9, 73, 2218, 549, 18, 31, 155, 36, 100, 763, 379, 20, 103, 351, 2, 13, 202, 12, 2241, 5, 6, 320, 46, 7, 457]),\n",
       "       list([1, 4, 204, 2, 20, 16, 93, 11, 2, 19, 2, 4390, 6, 55, 52, 22, 849, 4227, 119, 7, 2, 961, 178, 6, 1018, 221, 20, 1184, 2, 2, 29, 7, 265, 16, 530, 17, 29, 220, 210, 468, 8, 30, 11, 32, 7, 27, 102, 2, 3634, 17, 3278, 1881, 16, 6, 2, 7, 1262, 190, 4, 20, 122, 2353, 8, 79, 6, 117, 196, 11, 1370, 12, 127, 24, 847, 33, 4, 1062, 7, 4, 2, 310, 131, 12, 9, 6, 253, 20, 15, 144, 30, 110, 33, 222, 280]),\n",
       "       ...,\n",
       "       list([1, 4, 636, 457, 234, 520, 72, 440, 95, 2, 2085, 29, 64, 69, 31, 52, 326, 18, 4, 360, 7, 4, 20, 1557, 4588, 1141, 2, 486, 1350, 829, 6, 601, 2, 398, 57, 824, 11, 329, 74, 6, 1269, 43, 40, 4, 86, 31, 202, 2, 4, 4357, 5, 2, 90, 11, 6, 2768, 19, 1867, 3171, 5, 80, 2, 5, 92, 387, 90, 46, 366, 240, 1391, 6, 542, 229, 18, 142, 233, 29, 47, 12, 11, 90, 134, 2, 1722, 183, 26, 43, 2268, 10, 10, 387, 2, 4939, 209, 2]),\n",
       "       list([1, 45, 327, 8, 67, 6, 22, 19, 147, 84, 19, 1202, 1417, 2, 2, 9, 38, 427, 1078, 17, 6, 606, 246, 327, 577, 8, 670, 2, 10, 10, 37, 417, 11, 27, 236, 217, 214, 8, 123, 51, 6, 478, 284, 29, 16, 12, 9, 254, 8, 264, 15, 14, 9, 6, 628, 2219, 22, 12, 9, 550, 5, 60, 1047, 5, 728, 31, 7, 4, 118, 894, 25, 40, 519, 3227, 383, 139, 5, 567]),\n",
       "       list([1, 65, 7, 3957, 11, 4, 4609, 590, 14, 22, 9, 6, 307, 2, 7, 392, 58, 3957, 11, 4, 2, 590, 32, 4, 1366, 26, 50, 67, 1908, 1300, 2, 4, 1013, 4, 2, 2, 2, 2, 2, 2, 2313, 2, 2, 5, 2, 67, 14, 22, 235, 3957, 17, 12, 16, 10, 10])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 0, 1, 1]), (2773,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUWPA8buj2tq"
   },
   "source": [
    "## 2. Formater/Préparer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7BzHLIcj2tr",
    "outputId": "81469b2f-4540-4e2c-fa00-e4678850b580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La phrase avant padding est : \n",
      " [1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 2, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 2, 10, 10]\n",
      "La phrase paddée sur une longueur 100 est : \n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    1  778  128   74   12  630  163   15    4 1766    2 1051    2\n",
      "   32   85  156   45   40  148  139  121  664  665   10   10 1361  173\n",
      "    4  749    2   16 3804    8    4  226   65   12   43  127   24    2\n",
      "   10   10]\n",
      "2773\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# On padde les séquences\n",
    "\n",
    "print(\"La phrase avant padding est : \\n {}\". format(x_train[0]))\n",
    "\n",
    "# On padde les séquence de mot\n",
    "max_len     = 100\n",
    "x_train       =  pad_sequences(x_train, maxlen=max_len, truncating='post')\n",
    "x_test        = pad_sequences(x_test, maxlen=max_len, truncating='post')\n",
    "\n",
    "print(\"La phrase paddée sur une longueur {} est : \\n {}\". format(max_len, x_train[0]))\n",
    "      \n",
    "print(len(x_train))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC4r3IT1j2ts"
   },
   "source": [
    "## 3. Déclaration du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJE2oW-Xj2ts"
   },
   "source": [
    "La tâche consiste à prédire la valence d'un texte à partir de son contenu.\n",
    "Pour ce faire nous allons créer une architecture many-to-one \n",
    "avec les réseaux RNNs\n",
    "Le problème consiste à implémenter et apprendre\n",
    "des réseaux avec - par exemple - les configurations suivantes : \n",
    "On va comparer les configurations suivantes : \n",
    "- Simple RNN avec dropout (avec un taux de 25% en sortie du RNN)\n",
    "- RNN-LSTM gauche-droite classique\n",
    "- LSTM bi-directionnel et return_sequences = False\n",
    "- Plusieurs couches au choix. On veillera en particulier \n",
    "  à la valeur des arguments return_sequences\n",
    "  \n",
    "Dans le rapport à faire directement dans le notebook, on prendra soin de :\n",
    "- reporter les losses sur les ensembles d'entrainement et de validation\n",
    "- mesurer l'accuracy sur l'ensemble de test\n",
    "On commentera les résultats obtenus en comparant les configurations\n",
    "Quelle est la configuration donnant la meilleure performance ? \n",
    "Pourquoi ?\n",
    "\n",
    "Aide : une couche LSTM bi-directionnelle est obtenue en appliquant sur la même couche une couche LSTM et une couche Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up6fjdQjkzL9"
   },
   "source": [
    "# Simple RNN avec dropout (avec un taux de 25% en sortie du RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWA5HqtOj2ts",
    "outputId": "bb36cc99-104b-42f5-bf0f-e8dc73c02744"
   },
   "outputs": [],
   "source": [
    "# On importe les librairies pour le RNN\n",
    "from tensorflow.keras.layers import Dense , Input , SimpleRNN, LSTM , Embedding, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution1D,MaxPooling1D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import  Adam\n",
    "#from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "embed_size = 128                                                   # dimension de l'embedding\n",
    "RNN_size   = 64\n",
    "\n",
    "# Example d'architecture pour le réseau RNN simple avec dropout\n",
    "model_rnn_simple = Sequential()\n",
    "model_rnn_simple.add(Embedding(num_words, embed_size))                 # layer embedding\n",
    "model_rnn_simple.add(SimpleRNN(RNN_size, return_sequences = False))    # layer RNN\n",
    "model_rnn_simple.add(Dropout(0.25))                                    # layer Dropout\n",
    "model_rnn_simple.add(Dense(1))                                         # layer Dense\n",
    "\n",
    "# On affiche l'architecture de notre modèle\n",
    "model_rnn_simple.summary()\n",
    "\n",
    "# On spécifie la fonction de perte, l'optimiseur, et la fonction d'évaluation\n",
    "model_rnn_simple.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMDSWB90j2tt"
   },
   "source": [
    "## 4. Entrainement du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3r5Swu9j2tt",
    "outputId": "32222b14-79e4-4a4e-8816-c92769a7ea2b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On entraine le réseau\n",
    "batch_size = 64                                                             # tailles des mini-batch\n",
    "epochs = 10                                                                 # nombre d'époques\n",
    "history_rnn_simple = model_rnn_simple.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2) # on entraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "GaA4Vx2roRHx",
    "outputId": "cec90330-5133-4178-ac4c-c1f28d6c8ea1"
   },
   "outputs": [],
   "source": [
    "plot_history(history_rnn_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCDU-gito3bl",
    "outputId": "219e82ca-a680-4716-e8b9-6a104b54614f"
   },
   "outputs": [],
   "source": [
    "y_pred=predict(model_rnn_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tDluxcAj2tu",
    "outputId": "3a0bff92-dfef-4d45-f9fd-6b9ca6f66d23"
   },
   "outputs": [],
   "source": [
    "# On importe les librairies pour l'évaluation\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# On calcule la matrice de confusion\n",
    "cm_test = confusion_matrix(y_test, y_pred)\n",
    "print('La matrice de confusion sur le jeu de test :\\n', cm_test, '\\n')\n",
    "\n",
    "# On calcul le score d accuracy\n",
    "acc_train=accuracy_score(y_test, y_pred)\n",
    "print('L accuracy sur le jeu de test est :\\n', acc_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxsxTljC0Cpb"
   },
   "source": [
    "Comments : \n",
    "- l'accuracy n'est pas tres tres bonne, on remarque sur la matrice de confusion que nos données test ne sont pas tres bien predit ( 143 + 1025 ) sur l'ensemble de test qui sont mal classé . \n",
    "- notre model overfitt rapidement, ce qui fait qu'on ne peux pas l'entrainer plus. \n",
    "\n",
    "Tous les RNN ont des boucles de rétroaction dans la couche récurrente. Cela leur permet de conserver des informations en « mémoire » au fil du temps. Mais, il peut être difficile de former des RNN standard pour résoudre des problèmes qui nécessitent l'apprentissage de dépendances temporelles à long terme. C'est parce que le gradient de la fonction de perte décroît de façon exponentielle avec le temps  (problème de fuite de gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QbcGGkLkpwh"
   },
   "source": [
    "# RNN-LSTM gauche-droite classique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtoV899LnLsA",
    "outputId": "77ee885f-85c3-4185-ced3-4daf8ffd2173"
   },
   "outputs": [],
   "source": [
    "embed_size = 128                                                   # dimension de l'embedding\n",
    "RNN_size   = 64\n",
    "\n",
    "# Example d'architecture pour le réseau RNN simple avec dropout\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(num_words, embed_size))                 # layer embedding\n",
    "model_lstm.add(LSTM(RNN_size,return_sequences = False))          # layer lstm\n",
    "#model_lstm.add(Dropout(0.25))                                    # layer Dropout\n",
    "model_lstm.add(Dense(1))                                         # layer Dense\n",
    "\n",
    "# On affiche l'architecture de notre modèle\n",
    "model_lstm.summary()\n",
    "\n",
    "# On spécifie la fonction de perte, l'optimiseur, et la fonction d'évaluation\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kb1PMC2wn_mg",
    "outputId": "1d5fa6cb-2367-427c-c858-e129cde552c4"
   },
   "outputs": [],
   "source": [
    "# On entraine le réseau\n",
    "batch_size = 32                                                             # tailles des mini-batch\n",
    "epochs = 10                                                                 # nombre d'époques\n",
    "history_lstm = model_lstm.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2) # on entraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "VLcNnTM-oE8Z",
    "outputId": "877c1223-4fc9-4e5c-d040-74d5509c1d22"
   },
   "outputs": [],
   "source": [
    "plot_history(history_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPRDHs-AoE2G",
    "outputId": "f5ecd29f-398b-4b48-f799-29be6294290e"
   },
   "outputs": [],
   "source": [
    "y_pred=predict(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifPEcrXCri2N",
    "outputId": "3a243384-4143-4b4e-e18d-71216d09e175"
   },
   "outputs": [],
   "source": [
    "# On importe les librairies pour l'évaluation\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# On calcule la matrice de confusion\n",
    "cm_test = confusion_matrix(y_test, y_pred)\n",
    "print('La matrice de confusion sur le jeu de test :\\n', cm_test, '\\n')\n",
    "\n",
    "# On calcul le score d accuracy\n",
    "acc_train=accuracy_score(y_test, y_pred)\n",
    "print('L accuracy sur le jeu de test est :\\n', acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKA9vLSKxZbV"
   },
   "source": [
    "Comments :\n",
    "-  On a une accuracy bien meilleur avec le LSTM\n",
    "\n",
    "\n",
    "- Les réseaux LSTM sont un type de RNN qui utilise des unités spéciales en plus des unités standard. Les unités LSTM comprennent une « cellule mémoire » qui peut conserver des informations en mémoire pendant de longues périodes. Un ensemble de portes est utilisé pour contrôler quand les informations entrent dans la mémoire, quand elles sont sorties et quand elles sont oubliées. Cette architecture leur permet d'apprendre les dépendances à plus long terme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65KABuzVnCH4"
   },
   "source": [
    "# LSTM bi-directionnel et return_sequences = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwyZpOOIj2tu",
    "outputId": "63426e8f-544b-494a-8663-284acddaf9f7"
   },
   "outputs": [],
   "source": [
    "embed_size = 128                                                   # dimension de l'embedding\n",
    "RNN_size   = 64\n",
    "\n",
    "# Example d'architecture pour le réseau RNN simple avec dropout\n",
    "model_bidi = Sequential()\n",
    "model_bidi.add(Embedding(num_words, embed_size))                 # layer embedding\n",
    "model_bidi.add(Bidirectional(LSTM(RNN_size, return_sequences = False)))    # layer RNN\n",
    "#model_bidi.add(Dropout(0.25))                                    # layer Dropout\n",
    "model_bidi.add(Dense(1))                                         # layer Dense\n",
    "\n",
    "# On affiche l'architecture de notre modèle\n",
    "model_bidi.summary()\n",
    "\n",
    "# On spécifie la fonction de perte, l'optimiseur, et la fonction d'évaluation\n",
    "model_bidi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kr4BOFwNrYFn",
    "outputId": "77afe34c-f3f1-4965-938f-097efd7f77a0"
   },
   "outputs": [],
   "source": [
    "# On entraine le réseau\n",
    "batch_size = 32                                                            # tailles des mini-batch\n",
    "epochs = 10                                                                 # nombre d'époques\n",
    "history_bidi = model_bidi.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2) # on entraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "8L0pZg8mrXkS",
    "outputId": "1e4db2ec-c3c4-4ae4-bdac-828cba66e530"
   },
   "outputs": [],
   "source": [
    "plot_history(history_bidi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EP2pR3cvrXh8",
    "outputId": "fa156066-18f3-4f43-d731-1e0efbaba96f"
   },
   "outputs": [],
   "source": [
    "y_pred=predict(model_bidi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93W7k0MZrXfk",
    "outputId": "fb33c2c8-a2a4-45f9-970e-7455525e90c4"
   },
   "outputs": [],
   "source": [
    "# On importe les librairies pour l'évaluation\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# On calcule la matrice de confusion\n",
    "cm_test = confusion_matrix(y_test, y_pred)\n",
    "print('La matrice de confusion sur le jeu de test :\\n', cm_test, '\\n')\n",
    "\n",
    "# On calcul le score d accuracy\n",
    "acc_train=accuracy_score(y_test, y_pred)\n",
    "print('L accuracy sur le jeu de test est :\\n', acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDDingcLzFXB"
   },
   "source": [
    "L'accuracy est un peu plus meilleur que pour les LSTM bi\n",
    "\n",
    "L'utilisation de la bidirectionnelle exécutera nos entrées de deux manières, l'une du passé au futur et l'autre du futur au passé. Ce qui fait la difference avec les LSTM normal qui sont capables à tout moment de préserver les informations du passé et du futur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-CCd_x0nZBr"
   },
   "source": [
    "# Plusieurs couches LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-IbZE1inAEW",
    "outputId": "c0982810-4397-4477-88a7-ea4b9554d3fc"
   },
   "outputs": [],
   "source": [
    "embed_size = 64                                                 # dimension de l'embedding\n",
    "RNN_size   = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embed_size, mask_zero=True))   \n",
    "model.add(Bidirectional(LSTM(RNN_size,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# On spécifie la fonction de perte, l'optimiseur, et la fonction d'évaluation\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyQ8jHXU5XA3",
    "outputId": "d9d0307f-7603-47bc-cf74-5ab77cd31e0a"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train, epochs=10,\n",
    "                    validation_data=(x_test,y_test),\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "XiOwnhmHnXyY",
    "outputId": "2be42fde-ddb4-4f00-ac14-de9d4550ac9c"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHNPA8-UnXv4",
    "outputId": "12b2d818-8ad8-47b3-bfc2-9817a68ecd9d"
   },
   "outputs": [],
   "source": [
    "y_pred=predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ujusw8aBnXtk",
    "outputId": "ad66b91f-296e-4361-9071-c3154459894f"
   },
   "outputs": [],
   "source": [
    "# On importe les librairies pour l'évaluation\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# On calcule la matrice de confusion\n",
    "cm_test = confusion_matrix(y_test, y_pred)\n",
    "print('La matrice de confusion sur le jeu de test :\\n', cm_test, '\\n')\n",
    "\n",
    "# On calcul le score d accuracy\n",
    "acc_train=accuracy_score(y_test, y_pred)\n",
    "print('L accuracy sur le jeu de test est :\\n', acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_IF_6cqzscv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RNN_sentiment_analysis_problem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
